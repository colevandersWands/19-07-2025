{
  "type": "directory",
  "name": "test-content",
  "dir": "",
  "children": [
    {
      "type": "directory", 
      "name": "class-prep",
      "dir": "test-content",
      "children": [
        {
          "type": "file",
          "name": "complex-js.js",
          "ext": ".js",
          "base": "complex-js",
          "dir": "test-content/class-prep",
          "content": "// Complex JavaScript with multiple concepts\nclass DataProcessor {\n  constructor(config = {}) {\n    this.options = {\n      batchSize: 100,\n      timeout: 5000,\n      retries: 3,\n      ...config\n    };\n    this.queue = [];\n    this.processing = false;\n  }\n\n  async processData(items) {\n    if (this.processing) {\n      throw new Error('Already processing');\n    }\n\n    this.processing = true;\n    \n    try {\n      const batches = this.createBatches(items);\n      const results = [];\n      \n      for (const batch of batches) {\n        const batchResult = await this.processBatch(batch);\n        results.push(...batchResult);\n        \n        // Yield control to prevent blocking\n        await this.delay(0);\n      }\n      \n      return results;\n    } finally {\n      this.processing = false;\n    }\n  }\n\n  createBatches(items) {\n    const batches = [];\n    for (let i = 0; i < items.length; i += this.options.batchSize) {\n      batches.push(items.slice(i, i + this.options.batchSize));\n    }\n    return batches;\n  }\n\n  async processBatch(batch) {\n    return Promise.all(batch.map(item => this.processItem(item)));\n  }\n\n  async processItem(item) {\n    let attempts = 0;\n    \n    while (attempts < this.options.retries) {\n      try {\n        return await this.fetchData(item);\n      } catch (error) {\n        attempts++;\n        if (attempts === this.options.retries) {\n          throw error;\n        }\n        await this.delay(Math.pow(2, attempts) * 1000);\n      }\n    }\n  }\n\n  async fetchData(item) {\n    // Simulate API call\n    return new Promise((resolve, reject) => {\n      setTimeout(() => {\n        if (Math.random() > 0.1) {\n          resolve({ id: item.id, processed: true, timestamp: Date.now() });\n        } else {\n          reject(new Error(`Failed to process item ${item.id}`));\n        }\n      }, Math.random() * this.options.timeout);\n    });\n  }\n\n  delay(ms) {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n\n  // Generator function for streaming processing\n  async* streamProcess(items) {\n    for (const item of items) {\n      try {\n        const result = await this.processItem(item);\n        yield result;\n      } catch (error) {\n        yield { error: error.message, item };\n      }\n    }\n  }\n}\n\n// Usage examples\nconst processor = new DataProcessor({\n  batchSize: 50,\n  timeout: 3000\n});\n\nconst testData = Array.from({ length: 200 }, (_, i) => ({ id: i, data: `item-${i}` }));\n\n// Batch processing\nprocessor.processData(testData)\n  .then(results => console.log('Batch results:', results.length))\n  .catch(error => console.error('Batch error:', error));\n\n// Stream processing\n(async () => {\n  for await (const result of processor.streamProcess(testData)) {\n    console.log('Stream result:', result);\n  }\n})();",
          "path": "/test-content/class-prep/complex-js.js",
          "lang": ".js",
          "error": null
        },
        {
          "type": "file",
          "name": "react-component.jsx",
          "ext": ".jsx",
          "base": "react-component",
          "dir": "test-content/class-prep",
          "content": "import React, { useState, useEffect, useCallback, useMemo } from 'react';\nimport { debounce } from 'lodash';\n\nconst DataVisualization = ({ data, config = {} }) => {\n  const [filteredData, setFilteredData] = useState([]);\n  const [searchTerm, setSearchTerm] = useState('');\n  const [sortConfig, setSortConfig] = useState({ key: null, direction: 'asc' });\n  const [loading, setLoading] = useState(false);\n  const [error, setError] = useState(null);\n\n  // Memoized expensive calculations\n  const processedData = useMemo(() => {\n    if (!data) return [];\n    \n    return data.map(item => ({\n      ...item,\n      computed: item.value * config.multiplier || 1,\n      category: item.value > 100 ? 'high' : item.value > 50 ? 'medium' : 'low'\n    }));\n  }, [data, config.multiplier]);\n\n  // Debounced search to prevent excessive filtering\n  const debouncedSearch = useCallback(\n    debounce((term) => {\n      setLoading(true);\n      \n      // Simulate complex search operation\n      setTimeout(() => {\n        const filtered = processedData.filter(item => \n          item.name.toLowerCase().includes(term.toLowerCase()) ||\n          item.category.includes(term.toLowerCase())\n        );\n        \n        setFilteredData(filtered);\n        setLoading(false);\n      }, 300);\n    }, 500),\n    [processedData]\n  );\n\n  // Effect for search\n  useEffect(() => {\n    if (searchTerm) {\n      debouncedSearch(searchTerm);\n    } else {\n      setFilteredData(processedData);\n    }\n    \n    // Cleanup debounced function\n    return () => {\n      debouncedSearch.cancel();\n    };\n  }, [searchTerm, debouncedSearch, processedData]);\n\n  // Sorting logic\n  const handleSort = useCallback((key) => {\n    setSortConfig(prevConfig => ({\n      key,\n      direction: prevConfig.key === key && prevConfig.direction === 'asc' ? 'desc' : 'asc'\n    }));\n  }, []);\n\n  // Apply sorting\n  const sortedData = useMemo(() => {\n    if (!sortConfig.key) return filteredData;\n    \n    return [...filteredData].sort((a, b) => {\n      const aVal = a[sortConfig.key];\n      const bVal = b[sortConfig.key];\n      \n      if (aVal < bVal) return sortConfig.direction === 'asc' ? -1 : 1;\n      if (aVal > bVal) return sortConfig.direction === 'asc' ? 1 : -1;\n      return 0;\n    });\n  }, [filteredData, sortConfig]);\n\n  // Custom hooks for data export\n  const useDataExport = () => {\n    const exportCSV = useCallback(() => {\n      const csv = sortedData.map(item => \n        `${item.name},${item.value},${item.computed},${item.category}`\n      ).join('\\n');\n      \n      const blob = new Blob([csv], { type: 'text/csv' });\n      const url = URL.createObjectURL(blob);\n      const a = document.createElement('a');\n      a.href = url;\n      a.download = 'data-export.csv';\n      a.click();\n      URL.revokeObjectURL(url);\n    }, []);\n    \n    return { exportCSV };\n  };\n\n  const { exportCSV } = useDataExport();\n\n  // Error boundary-like error handling\n  const handleError = useCallback((error) => {\n    setError(error.message);\n    console.error('DataVisualization error:', error);\n  }, []);\n\n  if (error) {\n    return (\n      <div className=\"error-container\">\n        <h3>Something went wrong</h3>\n        <p>{error}</p>\n        <button onClick={() => setError(null)}>Try Again</button>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"data-visualization\">\n      <div className=\"controls\">\n        <input\n          type=\"text\"\n          placeholder=\"Search data...\"\n          value={searchTerm}\n          onChange={(e) => setSearchTerm(e.target.value)}\n          className=\"search-input\"\n        />\n        <button onClick={exportCSV} className=\"export-btn\">\n          Export CSV\n        </button>\n      </div>\n      \n      {loading && <div className=\"loading\">Filtering data...</div>}\n      \n      <table className=\"data-table\">\n        <thead>\n          <tr>\n            <th onClick={() => handleSort('name')} className=\"sortable\">\n              Name {sortConfig.key === 'name' && (sortConfig.direction === 'asc' ? '↑' : '↓')}\n            </th>\n            <th onClick={() => handleSort('value')} className=\"sortable\">\n              Value {sortConfig.key === 'value' && (sortConfig.direction === 'asc' ? '↑' : '↓')}\n            </th>\n            <th onClick={() => handleSort('computed')} className=\"sortable\">\n              Computed {sortConfig.key === 'computed' && (sortConfig.direction === 'asc' ? '↑' : '↓')}\n            </th>\n            <th onClick={() => handleSort('category')} className=\"sortable\">\n              Category {sortConfig.key === 'category' && (sortConfig.direction === 'asc' ? '↑' : '↓')}\n            </th>\n          </tr>\n        </thead>\n        <tbody>\n          {sortedData.map((item, index) => (\n            <tr key={item.id || index}>\n              <td>{item.name}</td>\n              <td>{item.value}</td>\n              <td>{item.computed.toFixed(2)}</td>\n              <td className={`category-${item.category}`}>{item.category}</td>\n            </tr>\n          ))}\n        </tbody>\n      </table>\n      \n      <div className=\"stats\">\n        <p>Showing {sortedData.length} of {processedData.length} items</p>\n      </div>\n    </div>\n  );\n};\n\nexport default DataVisualization;",
          "path": "/test-content/class-prep/react-component.jsx",
          "lang": ".jsx",
          "error": null
        },
        {
          "type": "file",
          "name": "spiral.json",
          "ext": ".json",
          "base": "spiral",
          "dir": "test-content/class-prep", 
          "content": "{\n  \"lenses\": {\n    \"embed\": {\n      \"template\": \"interactive\",\n      \"styles\": true,\n      \"title\": \"Class Preparation Material\",\n      \"features\": {\n        \"codeHighlight\": true,\n        \"lineNumbers\": true,\n        \"copyButton\": true\n      }\n    },\n    \"lines\": {\n      \"numbers\": true,\n      \"empty\": false,\n      \"prefix\": \"→ \",\n      \"highlight\": {\n        \"keywords\": [\"class\", \"function\", \"async\", \"await\"],\n        \"style\": \"bold\"\n      }\n    },\n    \"ast\": {\n      \"showTypes\": true,\n      \"expandDepth\": 3,\n      \"colorize\": true,\n      \"interactive\": true\n    }\n  },\n  \"defaults\": {\n    \".js\": [\"lines\", \"embed\"],\n    \".jsx\": [\"ast\", \"embed\"],\n    \".md\": [\"embed\"],\n    \".json\": [\"lines\"]\n  },\n  \"pipeline\": {\n    \"development\": [\"lines\", \"embed\"],\n    \"production\": [\"embed\"],\n    \"debug\": [\"lines\", \"ast\", \"embed\"]\n  }\n}",
          "path": "/test-content/class-prep/spiral.json",
          "lang": ".json",
          "error": null
        }
      ],
      "path": "/test-content/class-prep",
      "error": null
    },
    {
      "type": "directory",
      "name": "languages",
      "dir": "test-content", 
      "children": [
        {
          "type": "file",
          "name": "data-analysis.py",
          "ext": ".py",
          "base": "data-analysis",
          "dir": "test-content/languages",
          "content": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nfrom typing import List, Dict, Tuple, Optional\n\nclass DataAnalyzer:\n    \"\"\"Advanced data analysis pipeline with ML capabilities.\"\"\"\n    \n    def __init__(self, config: Dict = None):\n        self.config = {\n            'test_size': 0.2,\n            'random_state': 42,\n            'n_estimators': 100,\n            'max_depth': 10,\n            'visualization_style': 'seaborn',\n            **(config or {})\n        }\n        self.model = None\n        self.feature_importance = None\n        \n    def load_data(self, file_path: str) -> pd.DataFrame:\n        \"\"\"Load data from various file formats.\"\"\"\n        try:\n            if file_path.endswith('.csv'):\n                return pd.read_csv(file_path)\n            elif file_path.endswith('.json'):\n                return pd.read_json(file_path)\n            elif file_path.endswith('.xlsx'):\n                return pd.read_excel(file_path)\n            else:\n                raise ValueError(f\"Unsupported file format: {file_path}\")\n        except Exception as e:\n            print(f\"Error loading data: {e}\")\n            return pd.DataFrame()\n    \n    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"Clean and preprocess the dataset.\"\"\"\n        # Handle missing values\n        numeric_columns = df.select_dtypes(include=[np.number]).columns\n        df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].median())\n        \n        categorical_columns = df.select_dtypes(include=['object']).columns\n        df[categorical_columns] = df[categorical_columns].fillna(df[categorical_columns].mode().iloc[0])\n        \n        # Remove duplicates\n        df = df.drop_duplicates()\n        \n        # Feature engineering\n        for col in numeric_columns:\n            if df[col].std() > 0:\n                df[f'{col}_normalized'] = (df[col] - df[col].mean()) / df[col].std()\n                df[f'{col}_log'] = np.log1p(df[col].abs())\n        \n        return df\n    \n    def exploratory_analysis(self, df: pd.DataFrame) -> Dict:\n        \"\"\"Perform comprehensive exploratory data analysis.\"\"\"\n        analysis = {\n            'shape': df.shape,\n            'missing_values': df.isnull().sum().to_dict(),\n            'data_types': df.dtypes.to_dict(),\n            'numeric_summary': df.describe().to_dict(),\n            'correlations': df.corr().to_dict() if len(df.select_dtypes(include=[np.number]).columns) > 1 else {}\n        }\n        \n        # Detect outliers using IQR method\n        numeric_cols = df.select_dtypes(include=[np.number]).columns\n        outliers = {}\n        \n        for col in numeric_cols:\n            Q1 = df[col].quantile(0.25)\n            Q3 = df[col].quantile(0.75)\n            IQR = Q3 - Q1\n            lower_bound = Q1 - 1.5 * IQR\n            upper_bound = Q3 + 1.5 * IQR\n            outliers[col] = len(df[(df[col] < lower_bound) | (df[col] > upper_bound)])\n        \n        analysis['outliers'] = outliers\n        return analysis\n    \n    def create_visualizations(self, df: pd.DataFrame, target_column: str = None):\n        \"\"\"Generate comprehensive data visualizations.\"\"\"\n        plt.style.use(self.config['visualization_style'])\n        \n        # Set up the plotting area\n        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n        fig.suptitle('Comprehensive Data Analysis Dashboard', fontsize=16)\n        \n        numeric_cols = df.select_dtypes(include=[np.number]).columns[:5]\n        \n        # Distribution plots\n        for i, col in enumerate(numeric_cols[:3]):\n            axes[0, i].hist(df[col], bins=30, alpha=0.7, edgecolor='black')\n            axes[0, i].set_title(f'Distribution of {col}')\n            axes[0, i].set_xlabel(col)\n            axes[0, i].set_ylabel('Frequency')\n        \n        # Correlation heatmap\n        if len(numeric_cols) > 1:\n            corr_matrix = df[numeric_cols].corr()\n            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1, 0])\n            axes[1, 0].set_title('Correlation Heatmap')\n        \n        # Box plots for outlier detection\n        if len(numeric_cols) > 0:\n            df[numeric_cols[0]].plot(kind='box', ax=axes[1, 1])\n            axes[1, 1].set_title(f'Box Plot - {numeric_cols[0]}')\n        \n        # Target variable analysis (if provided)\n        if target_column and target_column in df.columns:\n            if df[target_column].dtype == 'object':\n                df[target_column].value_counts().plot(kind='bar', ax=axes[1, 2])\n                axes[1, 2].set_title(f'Target Distribution - {target_column}')\n            else:\n                axes[1, 2].hist(df[target_column], bins=30, alpha=0.7)\n                axes[1, 2].set_title(f'Target Distribution - {target_column}')\n        \n        plt.tight_layout()\n        return fig\n    \n    def train_model(self, df: pd.DataFrame, target_column: str, feature_columns: List[str] = None) -> Dict:\n        \"\"\"Train a machine learning model.\"\"\"\n        if target_column not in df.columns:\n            raise ValueError(f\"Target column '{target_column}' not found in dataset\")\n        \n        # Prepare features\n        if feature_columns is None:\n            feature_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n            if target_column in feature_columns:\n                feature_columns.remove(target_column)\n        \n        X = df[feature_columns]\n        y = df[target_column]\n        \n        # Split the data\n        X_train, X_test, y_train, y_test = train_test_split(\n            X, y, \n            test_size=self.config['test_size'],\n            random_state=self.config['random_state']\n        )\n        \n        # Train the model\n        self.model = RandomForestClassifier(\n            n_estimators=self.config['n_estimators'],\n            max_depth=self.config['max_depth'],\n            random_state=self.config['random_state']\n        )\n        \n        self.model.fit(X_train, y_train)\n        \n        # Make predictions\n        y_pred = self.model.predict(X_test)\n        \n        # Calculate feature importance\n        self.feature_importance = dict(zip(feature_columns, self.model.feature_importances_))\n        \n        # Generate performance metrics\n        results = {\n            'accuracy': self.model.score(X_test, y_test),\n            'classification_report': classification_report(y_test, y_pred, output_dict=True),\n            'feature_importance': self.feature_importance,\n            'confusion_matrix': confusion_matrix(y_test, y_pred).tolist(),\n            'test_size': len(X_test),\n            'train_size': len(X_train)\n        }\n        \n        return results\n    \n    def predict(self, new_data: pd.DataFrame) -> np.ndarray:\n        \"\"\"Make predictions on new data.\"\"\"\n        if self.model is None:\n            raise ValueError(\"Model not trained. Call train_model() first.\")\n        \n        return self.model.predict(new_data)\n    \n    def save_model(self, file_path: str):\n        \"\"\"Save the trained model.\"\"\"\n        import joblib\n        if self.model is None:\n            raise ValueError(\"No model to save. Train a model first.\")\n        \n        joblib.dump({\n            'model': self.model,\n            'feature_importance': self.feature_importance,\n            'config': self.config\n        }, file_path)\n    \n    def load_model(self, file_path: str):\n        \"\"\"Load a pre-trained model.\"\"\"\n        import joblib\n        data = joblib.load(file_path)\n        self.model = data['model']\n        self.feature_importance = data['feature_importance']\n        self.config.update(data['config'])\n\n# Example usage and testing\nif __name__ == \"__main__\":\n    # Initialize analyzer with custom configuration\n    analyzer = DataAnalyzer({\n        'test_size': 0.25,\n        'n_estimators': 150,\n        'max_depth': 15\n    })\n    \n    # Generate sample data for demonstration\n    np.random.seed(42)\n    sample_data = pd.DataFrame({\n        'feature1': np.random.normal(100, 15, 1000),\n        'feature2': np.random.exponential(2, 1000),\n        'feature3': np.random.uniform(0, 50, 1000),\n        'category': np.random.choice(['A', 'B', 'C'], 1000),\n        'target': np.random.choice([0, 1], 1000)\n    })\n    \n    # Perform analysis\n    print(\"Performing exploratory analysis...\")\n    eda_results = analyzer.exploratory_analysis(sample_data)\n    print(f\"Dataset shape: {eda_results['shape']}\")\n    print(f\"Missing values: {eda_results['missing_values']}\")\n    \n    # Create visualizations\n    print(\"Generating visualizations...\")\n    fig = analyzer.create_visualizations(sample_data, 'target')\n    \n    # Train model\n    print(\"Training model...\")\n    results = analyzer.train_model(sample_data, 'target', ['feature1', 'feature2', 'feature3'])\n    print(f\"Model accuracy: {results['accuracy']:.4f}\")\n    print(f\"Feature importance: {results['feature_importance']}\")\n    \n    print(\"Analysis complete!\")",
          "path": "/test-content/languages/data-analysis.py", 
          "lang": ".py",
          "error": null
        }
      ],
      "path": "/test-content/languages",
      "error": null
    }
  ],
  "path": "/test-content",
  "error": null
}